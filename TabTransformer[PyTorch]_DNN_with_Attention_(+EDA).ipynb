{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "TabTransformer[PyTorch]: DNN with Attention (+EDA)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuyesu/Python-data-tools/blob/main/TabTransformer%5BPyTorch%5D_DNN_with_Attention_(%2BEDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# [Spaceship Titanic][1]\n",
        "\n",
        "We are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceshipâ€™s damaged computer system.\n",
        "\n",
        "---\n",
        "## The aim of this notebook is to implement TabTransformer model from scratch with PyTorch.\n",
        "\n",
        "---\n",
        "TabTransformer is a deep neural network for tabular data modeling built upon self-attention mechanism. The model architecture is as follows:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/keras-team/keras-io/master/examples/structured_data/img/tabtransformer/tabtransformer.png\" width=\"400\"/>\n",
        "\n",
        "- I explained and implemented TabTransformer in <a href=\"#4.2\">Chapter4.2</a>.\n",
        "- For a deeper understanding of TabTransformer, please refer to the original paper: [TabTransformer: Tabular Data Modeling Using Contextual Embeddings](https://arxiv.org/abs/2012.06678).\n",
        "\n",
        "---\n",
        "**References:** Thanks to previous great codes and notebooks.\n",
        "- [ðŸ”¥ðŸ”¥[TensorFlow]TabTransformerðŸ”¥ðŸ”¥][2]\n",
        "- [Structured data learning with TabTransformer][3]\n",
        "\n",
        "**My Previous Notebooks:**\n",
        "\n",
        "- I have implemented TabTransformer from scratch with TensorFlow in [SpaceshipTitanic: EDA + TabTransformer[TensorFlow]][4].\n",
        "- Please note that EDA and Feature Engineering parts in this notebook are same as my previous notebooks below. If you have read it, you can <a href=\"#4\">skip over chapter3</a>.\n",
        " - [SpaceshipTitanic: EDA + TabTransformer[TensorFlow]][4]\n",
        " - [TabNet: DNN+DecisionTree [Library & fromScratch]][5]\n",
        "\n",
        "---\n",
        "### **If you find this notebook useful, or when you copy&edit this notebook, please do give me an upvote. It helps me keep up my motivation.**\n",
        "\n",
        "---\n",
        "[1]: https://www.kaggle.com/competitions/spaceship-titanic/overview\n",
        "[2]: https://www.kaggle.com/code/usharengaraju/tensorflow-tabtransformer\n",
        "[3]: https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/structured_data/ipynb/tabtransformer.ipynb\n",
        "[4]: https://www.kaggle.com/code/masatomurakawamm/spaceshiptitanic-eda-tabtransformer-tensorflow\n",
        "[5]: https://www.kaggle.com/code/masatomurakawamm/tabnet-dnn-decisiontree-library-fromscratch"
      ],
      "metadata": {
        "id": "Z_6eMNfPvfWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span id='toc'/>\n",
        "\n",
        "<h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>0. TABLE OF CONTENTS</center></h1>\n",
        "\n",
        "<ul class=\"list-group\" style=\"list-style-type:none;\">\n",
        "    <li><a href=\"#1\" class=\"list-group-item list-group-item-action\">1. Settings</a></li>\n",
        "    <li><a href=\"#2\" class=\"list-group-item list-group-item-action\">2. Data Loading</a></li>\n",
        "    <li><a href=\"#3\" class=\"list-group-item list-group-item-action\">3. EDA and Feature Engineering</a>\n",
        "        <ul class=\"list-group\" style=\"list-style-type:none;\">\n",
        "            <li><a href=\"#3.1\" class=\"list-group-item list-group-item-action\">3.1 Exploratory Data Analysis</a></li>\n",
        "            <li><a href=\"#3.2\" class=\"list-group-item list-group-item-action\">3.2 Dataset</a></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><a href=\"#4\" class=\"list-group-item list-group-item-action\">4. Model</a>\n",
        "        <ul class=\"list-group\" style=\"list-style-type:none;\">\n",
        "            <li><a href=\"#4.1\" class=\"list-group-item list-group-item-action\">4.1 Preprocessing Model</a></li>\n",
        "            <li><a href=\"#4.2\" class=\"list-group-item list-group-item-action\">4.2 TabTransformer</a></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><a href=\"#5\" class=\"list-group-item list-group-item-action\">5. Training</a></li>\n",
        "    <li><a href=\"#6\" class=\"list-group-item list-group-item-action\">6. Prediction</a></li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "8ux6Qpy1vfWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"1\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>1. Settings</center></h1>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "2RWJRul5vfWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Parameters\n",
        "data_config = {\n",
        "    'train_csv_path': '../input/spaceship-titanic/train.csv',\n",
        "    'test_csv_path': '../input/spaceship-titanic/test.csv',\n",
        "    'sample_submission_path': '../input/spaceship-titanic/sample_submission.csv',\n",
        "}\n",
        "\n",
        "exp_config = {\n",
        "    'n_bins': 10,\n",
        "    'n_splits': 5,\n",
        "    'batch_size': 512,\n",
        "    'learning_rate': 2e-4,\n",
        "    'weight_decay': 0.0001,\n",
        "    'train_epochs': 15,\n",
        "    'finalize': True,\n",
        "    'finalize_epochs': 8,\n",
        "}\n",
        "\n",
        "model_config = {\n",
        "    'cat_embedding_dim': 12,\n",
        "    'num_transformer_blocks': 4,\n",
        "    'num_heads': 3,\n",
        "    'tf_dropout_rates': [0., 0., 0., 0.,],\n",
        "    'ff_dropout_rates': [0., 0., 0., 0.,],\n",
        "    'mlp_dropout_rates': [0.2, 0.1],\n",
        "    'mlp_hidden_units_factors': [2, 1],\n",
        "}\n",
        "\n",
        "print('Parameters setted!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:22:52.157448Z",
          "iopub.execute_input": "2022-09-13T14:22:52.158212Z",
          "iopub.status.idle": "2022-09-13T14:22:52.190384Z",
          "shell.execute_reply.started": "2022-09-13T14:22:52.15811Z",
          "shell.execute_reply": "2022-09-13T14:22:52.189429Z"
        },
        "trusted": true,
        "id": "hqOzl2R_vfWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import os, sys, pathlib, gc\n",
        "import re, math, random, time\n",
        "import datetime as dt\n",
        "from tqdm import tqdm\n",
        "from typing import Optional, Union, Tuple\n",
        "from collections import OrderedDict\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('import done!')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:22:52.192044Z",
          "iopub.execute_input": "2022-09-13T14:22:52.192567Z",
          "iopub.status.idle": "2022-09-13T14:23:03.464668Z",
          "shell.execute_reply.started": "2022-09-13T14:22:52.192536Z",
          "shell.execute_reply": "2022-09-13T14:23:03.463792Z"
        },
        "trusted": true,
        "id": "piWGr6gJvfWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For reproducible results\n",
        "def seed_all(s):\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    tf.random.set_seed(s)\n",
        "    torch.manual_seed(s)\n",
        "    torch.cuda.manual_seed(s)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    os.environ['PYTHONHASHSEED'] = str(s)\n",
        "    print('Seeds setted!')\n",
        "global_seed = 42\n",
        "seed_all(global_seed)\n",
        "\n",
        "## Limit GPU Memory in TensorFlow\n",
        "## Because TensorFlow, by default, allocates the full amount of available GPU memory when it is launched.\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
        "else:\n",
        "    print(\"Not enough GPU hardware devices available\")\n",
        "\n",
        "## For Seaborn Setting\n",
        "custom_params = {\n",
        "    \"axes.spines.right\": False,\n",
        "    \"axes.spines.top\": False,\n",
        "    'grid.alpha': 0.3,\n",
        "    'figure.figsize': (16, 6),\n",
        "    'axes.titlesize': 'Large',\n",
        "    'axes.labelsize': 'Large',\n",
        "    'figure.facecolor': '#fdfcf6',\n",
        "    'axes.facecolor': '#fdfcf6',\n",
        "}\n",
        "cluster_colors = ['#b4d2b1', '#568f8b', '#1d4a60', '#cd7e59', '#ddb247', '#d15252']\n",
        "sns.set_theme(\n",
        "    style='whitegrid',\n",
        "    #palette=sns.color_palette(cluster_colors),\n",
        "    rc=custom_params,)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.466047Z",
          "iopub.execute_input": "2022-09-13T14:23:03.467482Z",
          "iopub.status.idle": "2022-09-13T14:23:03.491893Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.467445Z",
          "shell.execute_reply": "2022-09-13T14:23:03.490573Z"
        },
        "trusted": true,
        "id": "_K6syfuAvfWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"2\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>2. Data Loading</center></h1>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "MvWVQeQ0vfWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### [File and Data Field Descriptions](https://www.kaggle.com/competitions/spaceship-titanic/data)\n",
        "\n",
        "- **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
        " - `PassengerId` - A unique Id for each passenger. Each Id takes the form `gggg_pp` where `gggg` indicates a group the passenger is travelling with and `pp` is their number within the group. People in a group are often family members, but not always.\n",
        " - `HomePlanet` - The planet the passenger departed from, typically their planet of permanent residence.\n",
        " - `CryoSleep` - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
        " - `Cabin` - The cabin number where the passenger is staying. Takes the form `deck/num/side`, where `side` can be either `P` for *Port* or `S` for *Starboard*.\n",
        " - `Destination` - The planet the passenger will be debarking to.\n",
        " - `Age` - The age of the passenger.\n",
        " - `VIP` - Whether the passenger has paid for special VIP service during the voyage.\n",
        " - `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck` - Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities.\n",
        " - `Name` - The first and last names of the passenger.\n",
        " - `Transported` - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
        "\n",
        "\n",
        "- **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of `Transported` for the passengers in this set.\n",
        "\n",
        "\n",
        "- **sample_submission.csv** - A submission file in the correct format.\n",
        " - `PassengerId` - Id for each passenger in the test set.\n",
        " - `Transported` - The target. For each passenger, predict either *True* or *False*.\n",
        "\n",
        "---\n",
        "### [Submission & Evaluation](https://www.kaggle.com/competitions/spaceship-titanic/overview/evaluation)\n",
        "\n",
        "- Submissions are evaluated based on their classification accuracy, the percentage of predicted labels that are correct.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Y1n-5AVTvfWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Loading\n",
        "train_df = pd.read_csv(data_config['train_csv_path'])\n",
        "test_df = pd.read_csv(data_config['test_csv_path'])\n",
        "submission_df = pd.read_csv(data_config['sample_submission_path'])\n",
        "\n",
        "print(f'train_length: {len(train_df)}')\n",
        "print(f'test_lenght: {len(test_df)}')\n",
        "print(f'submission_length: {len(submission_df)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.494906Z",
          "iopub.execute_input": "2022-09-13T14:23:03.495639Z",
          "iopub.status.idle": "2022-09-13T14:23:03.602106Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.495593Z",
          "shell.execute_reply": "2022-09-13T14:23:03.600779Z"
        },
        "trusted": true,
        "id": "AYBs3q_EvfWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Null Value Check\n",
        "print('train_df.info()'); print(train_df.info(), '\\n')\n",
        "print('test_df.info()'); print(test_df.info(), '\\n')\n",
        "\n",
        "## train_df Check\n",
        "train_df.head()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.60502Z",
          "iopub.execute_input": "2022-09-13T14:23:03.606164Z",
          "iopub.status.idle": "2022-09-13T14:23:03.670728Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.606118Z",
          "shell.execute_reply": "2022-09-13T14:23:03.669657Z"
        },
        "trusted": true,
        "id": "VBv5taFgvfWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "There are some missing values.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7sTTbocnvfWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"3\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>3. EDA and Feature Engineering</center></h1>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "RkYAhng0vfWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Data Preprocessing</center></h2>"
      ],
      "metadata": {
        "id": "7yhzXSFHvfWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Feature Selection\n",
        "numerical_columns = ['Age', 'RoomService', 'FoodCourt',\n",
        "                     'ShoppingMall', 'Spa', 'VRDeck']\n",
        "categorical_columns = ['PassengerId', 'HomePlanet', 'CryoSleep',\n",
        "                       'Cabin', 'Destination', 'VIP', 'Name']\n",
        "target = 'Transported'\n",
        "\n",
        "## Number of unique values in each categorical features.\n",
        "categorical_n_unique = {cc: train_df[cc].nunique() \\\n",
        "                        for cc in categorical_columns}\n",
        "categorical_n_unique"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.67209Z",
          "iopub.execute_input": "2022-09-13T14:23:03.672433Z",
          "iopub.status.idle": "2022-09-13T14:23:03.690599Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.672401Z",
          "shell.execute_reply": "2022-09-13T14:23:03.688918Z"
        },
        "trusted": true,
        "id": "Gy65Lhr5vfWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function for Data Preprocessing\n",
        "def preprocess_df(dataframe):\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    ## Drop 'Name'\n",
        "    df = df.drop(['Name'], axis=1)\n",
        "\n",
        "    ## Transform 'Transported' column to 0 or 1.\n",
        "    if 'Transported' in df.columns:\n",
        "        df.loc[df['Transported']==True, 'Transported'] = 1.\n",
        "        df.loc[df['Transported']==False, 'Transported'] = 0.\n",
        "        df['Transported'] = df['Transported'].astype('int64')\n",
        "\n",
        "    ## Transform True-False features (CryoSleep and VIP) to 'Yes' or 'No'.\n",
        "    df.loc[df['CryoSleep']==True, 'CryoSleep'] = 'Yes'\n",
        "    df.loc[df['CryoSleep']==False, 'CryoSleep'] = 'No'\n",
        "    df['CryoSleep'] = df['CryoSleep'].astype(str)\n",
        "\n",
        "    df.loc[df['VIP']==True, 'VIP'] = 'Yes'\n",
        "    df.loc[df['VIP']==False, 'VIP'] = 'No'\n",
        "    df['VIP'] = df['VIP'].astype(str)\n",
        "\n",
        "    ## Transform the dtypes of HomePlanet and Destination to str\n",
        "    df['HomePlanet'] = df['HomePlanet'].astype(str)\n",
        "    df['Destination'] = df['Destination'].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = preprocess_df(train_df)\n",
        "train.head()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.694115Z",
          "iopub.execute_input": "2022-09-13T14:23:03.694968Z",
          "iopub.status.idle": "2022-09-13T14:23:03.739205Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.694926Z",
          "shell.execute_reply": "2022-09-13T14:23:03.737863Z"
        },
        "trusted": true,
        "id": "q4SoN9BjvfWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caution: After `astype(str)`, null values (np.nan) are replaced by the string 'nan'.**"
      ],
      "metadata": {
        "id": "kM4MsIbIvfWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Handle 'Cabin' feature\n",
        "def cabin_split(dataframe):\n",
        "    df = dataframe.copy()\n",
        "\n",
        "    df['Cabin'] = df['Cabin'].astype(str)\n",
        "    cabins = df['Cabin'].str.split('/', expand=True)\n",
        "    cabins.columns = ['Cabin_0', 'Cabin_1', 'Cabin_2']\n",
        "\n",
        "    df = pd.concat([df, cabins], axis=1)\n",
        "    df = df.drop(['Cabin'], axis=1)\n",
        "    df['Cabin_0'].astype(str)\n",
        "    df['Cabin_1'] = pd.to_numeric(df['Cabin_1'], errors='coerce')\n",
        "    df['Cabin_2'].astype(str)\n",
        "    df['Cabin_2'] = df['Cabin_2'].map(lambda x: 'nan' if x is None else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = cabin_split(train)\n",
        "train.head()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.741018Z",
          "iopub.execute_input": "2022-09-13T14:23:03.742146Z",
          "iopub.status.idle": "2022-09-13T14:23:03.807767Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.7421Z",
          "shell.execute_reply": "2022-09-13T14:23:03.806539Z"
        },
        "trusted": true,
        "id": "6i6itgMGvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"3.1\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.1 Exploratory Data Analysis</center></h2>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "NWsbjwbIvfWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"3.1.1\"></a><h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Target Distribution </center></h2>"
      ],
      "metadata": {
        "id": "0Mv8tfNhvfWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Count positive and negative 'Transported'\n",
        "train_pos = train.query('Transported==1').reset_index(drop=True)\n",
        "train_neg = train.query('Transported==0').reset_index(drop=True)\n",
        "print(f'positive samples: {len(train_pos)}, negative samples: {len(train_neg)}')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.809205Z",
          "iopub.execute_input": "2022-09-13T14:23:03.809545Z",
          "iopub.status.idle": "2022-09-13T14:23:03.829515Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.809514Z",
          "shell.execute_reply": "2022-09-13T14:23:03.82838Z"
        },
        "trusted": true,
        "id": "9bGG0ZkdvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Target Distribution\n",
        "target_count = train.groupby(['Transported'])['PassengerId'].count()\n",
        "target_percent = target_count / target_count.sum()\n",
        "\n",
        "fig = go.Figure()\n",
        "data = go.Bar(x=target_count.index.astype(str).values,\n",
        "              y=target_count.values)\n",
        "fig.add_trace(data)\n",
        "fig.update_layout(title = dict(text=\"Target distribution\"),\n",
        "                  xaxis = dict(title=\"'Transported' values\"),\n",
        "                  yaxis = dict(title='counts'))\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.833459Z",
          "iopub.execute_input": "2022-09-13T14:23:03.834016Z",
          "iopub.status.idle": "2022-09-13T14:23:03.964152Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.833981Z",
          "shell.execute_reply": "2022-09-13T14:23:03.962867Z"
        },
        "trusted": true,
        "id": "6R-NEM8YvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Numerical Features </center></h2>"
      ],
      "metadata": {
        "id": "BtuZM1kEvfWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Statistics of Numerical Features\n",
        "train.describe().T.style.bar(subset=['mean'],)\\\n",
        "                        .background_gradient(subset=['std'], cmap='coolwarm')\\\n",
        "                        .background_gradient(subset=['50%'], cmap='coolwarm')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:03.966108Z",
          "iopub.execute_input": "2022-09-13T14:23:03.966586Z",
          "iopub.status.idle": "2022-09-13T14:23:04.074861Z",
          "shell.execute_reply.started": "2022-09-13T14:23:03.966541Z",
          "shell.execute_reply": "2022-09-13T14:23:04.073749Z"
        },
        "trusted": true,
        "id": "3HuzxjjyvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Statistics based on 'Transported' (pos or neg)\n",
        "train.groupby('Transported').describe().T"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:04.076567Z",
          "iopub.execute_input": "2022-09-13T14:23:04.077018Z",
          "iopub.status.idle": "2022-09-13T14:23:04.143112Z",
          "shell.execute_reply.started": "2022-09-13T14:23:04.076976Z",
          "shell.execute_reply": "2022-09-13T14:23:04.141966Z"
        },
        "trusted": true,
        "id": "RQf8U2v7vfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Values at 90, 95, 98, 99, 100 % quantiles.\n",
        "quantiles = [0.9, 0.95, 0.98, 0.99, 1]\n",
        "train_quantile_values = train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].quantile(quantiles)\n",
        "train_quantile_values"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:04.144587Z",
          "iopub.execute_input": "2022-09-13T14:23:04.145392Z",
          "iopub.status.idle": "2022-09-13T14:23:04.164827Z",
          "shell.execute_reply.started": "2022-09-13T14:23:04.145347Z",
          "shell.execute_reply": "2022-09-13T14:23:04.164016Z"
        },
        "trusted": true,
        "id": "E6WxuQgEvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### There seems to be outliers...\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cJfi6RtUvfWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Clipping outliers on 99% quantile\n",
        "def clipping_quantile(dataframe, quantile_values=None, quantile=0.99):\n",
        "    df = dataframe.copy()\n",
        "    if quantile_values is None:\n",
        "        quantile_values = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].quantile(quantile)\n",
        "\n",
        "    for num_column in ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
        "        num_values = df[num_column].values\n",
        "        threshold = quantile_values[num_column]\n",
        "        num_values = np.where(num_values > threshold, threshold, num_values)\n",
        "        df[num_column] = num_values\n",
        "    return df\n",
        "\n",
        "train = clipping_quantile(train, quantile_values=None, quantile=0.99)\n",
        "\n",
        "## Statistics after clipping outliers\n",
        "train.describe().T.style.bar(subset=['mean'],)\\\n",
        "                        .background_gradient(subset=['std'], cmap='coolwarm')\\\n",
        "                        .background_gradient(subset=['50%'], cmap='coolwarm')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:04.166234Z",
          "iopub.execute_input": "2022-09-13T14:23:04.166547Z",
          "iopub.status.idle": "2022-09-13T14:23:04.217734Z",
          "shell.execute_reply.started": "2022-09-13T14:23:04.166518Z",
          "shell.execute_reply": "2022-09-13T14:23:04.216657Z"
        },
        "trusted": true,
        "id": "QCQcHiABvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Statistics based on 'Transported' (after Clipping Outliers)\n",
        "train.groupby('Transported').describe().T"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:04.219166Z",
          "iopub.execute_input": "2022-09-13T14:23:04.220204Z",
          "iopub.status.idle": "2022-09-13T14:23:04.282857Z",
          "shell.execute_reply.started": "2022-09-13T14:23:04.22016Z",
          "shell.execute_reply": "2022-09-13T14:23:04.281651Z"
        },
        "trusted": true,
        "id": "U6JB_WljvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Distribution of Numerical Features after Clipping Outliers\n",
        "n_cols = 2\n",
        "n_rows = int(np.ceil(len(numerical_columns) / n_cols))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_rows,ncols=n_cols,figsize=(20,15))\n",
        "\n",
        "bins = 50\n",
        "for i, column in enumerate(numerical_columns):\n",
        "    q, mod = divmod(i, n_cols)\n",
        "    sns.histplot(x=column, data=train,\n",
        "                 hue='Transported', ax=axes[q][mod],\n",
        "                 bins=bins, stat=\"percent\",\n",
        "                 kde=True, legend=True)\n",
        "    axes[q][mod].set_title(f'Distribution of {numerical_columns[i]}',size=15)\n",
        "\n",
        "fig.suptitle('Blue: Transported=0, Red: Transported=1', fontsize=20)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:04.284351Z",
          "iopub.execute_input": "2022-09-13T14:23:04.28522Z",
          "iopub.status.idle": "2022-09-13T14:23:07.909852Z",
          "shell.execute_reply.started": "2022-09-13T14:23:04.28517Z",
          "shell.execute_reply": "2022-09-13T14:23:07.908909Z"
        },
        "trusted": true,
        "id": "zBIbP-uvvfWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Heat Map of Correlation Matrix\n",
        "fig = px.imshow(\n",
        "    train.corr(),\n",
        "    color_continuous_scale='RdBu_r',\n",
        "    color_continuous_midpoint=0,\n",
        "    aspect='auto'\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=500,\n",
        "    width=500,\n",
        "    title=\"Heatmap\",\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:07.911255Z",
          "iopub.execute_input": "2022-09-13T14:23:07.912203Z",
          "iopub.status.idle": "2022-09-13T14:23:08.783701Z",
          "shell.execute_reply.started": "2022-09-13T14:23:07.912157Z",
          "shell.execute_reply": "2022-09-13T14:23:08.782582Z"
        },
        "trusted": true,
        "id": "G8rLb4SJvfWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binning Numerical Features\n",
        "\n",
        "---\n",
        "Binning Method\n",
        "- `Age`: 0 to 100 at intervals of 5.\n",
        "- `other numerical features`: Split into 10 bins.\n",
        " - 1. Value=0 is the first bin ( get by (-1, 0] ).\n",
        " - 2. Get quantiles at [ 0, 0.9, 0.95, 0.99, 1 ].\n",
        " - 3. Split between quantiles_0 and quantiles_0.9 into 6 bins.\n",
        " - 4. Use quantiles_0.95, _0.99, _1 for the rest boundary.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xwl3uTWVvfWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper Functions\n",
        "def bin_split(dataframe, column, n_bins, thresholds=None):\n",
        "    if thresholds is None:\n",
        "        if column == 'Age':\n",
        "            bins = np.array([i*5 for i in range(21)])\n",
        "        else:\n",
        "            bins = np.array([-1, ])\n",
        "            x = dataframe[column]\n",
        "            x_quantiles = x.quantile([0, 0.9, 0.95, 0.99, 1])\n",
        "            bins = np.append(bins, [i * ((x_quantiles.iloc[1] - x_quantiles.iloc[0]) / (n_bins-4)) for i in range(n_bins-4)])\n",
        "            bins = np.append(bins, [x_quantiles.iloc[1], x_quantiles.iloc[2], x_quantiles.iloc[3], x_quantiles.iloc[4]+1])\n",
        "    else:\n",
        "        bins = thresholds[column]\n",
        "\n",
        "    splits = pd.cut(dataframe[column], bins=bins, labels=False, right=True)\n",
        "    return splits, bins\n",
        "\n",
        "def binning(dataframe, numerical_columns, n_bins, thresholds=None):\n",
        "    df = dataframe.copy()\n",
        "    df_split_bins = {}\n",
        "    for num_column in numerical_columns:\n",
        "        splits, bins = bin_split(df, num_column, n_bins, thresholds)\n",
        "        df[num_column] = splits\n",
        "        df_split_bins[num_column] = bins\n",
        "    return df, df_split_bins\n",
        "\n",
        "n_bins = exp_config['n_bins']\n",
        "train, train_split_bins = binning(train, numerical_columns, n_bins, thresholds=None)\n",
        "\n",
        "for key in train_split_bins:\n",
        "    print(f'{key} bins: \\n{train_split_bins[key]}\\n\\n')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:08.785048Z",
          "iopub.execute_input": "2022-09-13T14:23:08.785493Z",
          "iopub.status.idle": "2022-09-13T14:23:08.815801Z",
          "shell.execute_reply.started": "2022-09-13T14:23:08.78546Z",
          "shell.execute_reply": "2022-09-13T14:23:08.814812Z"
        },
        "trusted": true,
        "id": "KjFaPf1_vfWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Distribution of Numerical Features after Binning\n",
        "n_cols = 2\n",
        "n_rows = int(np.ceil(len(numerical_columns) / n_cols))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(20,15))\n",
        "\n",
        "bins = 50\n",
        "for i, column in enumerate(numerical_columns):\n",
        "    q, mod = divmod(i, n_cols)\n",
        "    sns.histplot(\n",
        "        x=column,\n",
        "        data=train,\n",
        "        hue='Transported',\n",
        "        ax=axes[q][mod],\n",
        "        bins=bins,\n",
        "        stat=\"percent\",\n",
        "        legend=True\n",
        "    )\n",
        "    axes[q][mod].set_title(f'Distribution of {numerical_columns[i]}',size=15)\n",
        "\n",
        "fig.suptitle('Blue: Transported=0, Red: Transported=1', fontsize=20)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:08.816932Z",
          "iopub.execute_input": "2022-09-13T14:23:08.817554Z",
          "iopub.status.idle": "2022-09-13T14:23:11.958902Z",
          "shell.execute_reply.started": "2022-09-13T14:23:08.817516Z",
          "shell.execute_reply": "2022-09-13T14:23:11.957682Z"
        },
        "trusted": true,
        "id": "9yLVIyOVvfWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"3.1.3\"></a><h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Categorical Features</center></h2>"
      ],
      "metadata": {
        "id": "xrFFdL3IvfWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Distribution of Categorical Features\n",
        "categorical_columns = ['HomePlanet', 'CryoSleep',\n",
        "                       'Destination', 'VIP']\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=categorical_columns,\n",
        "    shared_yaxes='all'\n",
        ")\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        n = i*2 + j\n",
        "        data0 = go.Histogram(\n",
        "            x=train_neg[categorical_columns[n]],\n",
        "            marker = dict(color='#0000FF'), ## Blue\n",
        "            name='Transporetd=0'\n",
        "        )\n",
        "        data1 = go.Histogram(\n",
        "            x=train_pos[categorical_columns[n]],\n",
        "            marker = dict(color='#FF0000'), ## Red\n",
        "            name='Transported=1'\n",
        "        )\n",
        "\n",
        "        fig.add_trace(data0, row=i+1, col=j+1)\n",
        "        fig.add_trace(data1, row=i+1, col=j+1)\n",
        "\n",
        "        fig.update_traces(opacity=0.75, histnorm='probability')\n",
        "        #fig.update_layout(barmode='overlay')\n",
        "\n",
        "fig.update_layout(title = dict(text='Blue: Transported=0, Red: Transported=1'),\n",
        "                  showlegend=False,)\n",
        "fig.update_yaxes(title='probability', row=1, col=1)\n",
        "fig.update_yaxes(title='probability', row=2, col=1)\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:11.960583Z",
          "iopub.execute_input": "2022-09-13T14:23:11.96096Z",
          "iopub.status.idle": "2022-09-13T14:23:12.197542Z",
          "shell.execute_reply.started": "2022-09-13T14:23:11.960926Z",
          "shell.execute_reply": "2022-09-13T14:23:12.196258Z"
        },
        "trusted": true,
        "id": "TlsOgeVYvfWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Cabin Features</center></h2>"
      ],
      "metadata": {
        "id": "DkMAzAtJvfWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 'Cabin_0'\n",
        "sns.countplot(x='Cabin_0', data=train, hue='Transported')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:12.199214Z",
          "iopub.execute_input": "2022-09-13T14:23:12.199661Z",
          "iopub.status.idle": "2022-09-13T14:23:12.554225Z",
          "shell.execute_reply.started": "2022-09-13T14:23:12.19962Z",
          "shell.execute_reply": "2022-09-13T14:23:12.552928Z"
        },
        "trusted": true,
        "id": "v-O_PWaMvfWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 'Cabin_1'\n",
        "sns.histplot(x='Cabin_1', data=train, hue='Transported', kde=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:12.555907Z",
          "iopub.execute_input": "2022-09-13T14:23:12.559868Z",
          "iopub.status.idle": "2022-09-13T14:23:13.065122Z",
          "shell.execute_reply.started": "2022-09-13T14:23:12.559826Z",
          "shell.execute_reply": "2022-09-13T14:23:13.063951Z"
        },
        "trusted": true,
        "id": "QsoXTZuUvfWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 'Cabin_2'\n",
        "sns.countplot(x='Cabin_2', data=train, hue='Transported')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.066459Z",
          "iopub.execute_input": "2022-09-13T14:23:13.06681Z",
          "iopub.status.idle": "2022-09-13T14:23:13.314623Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.066779Z",
          "shell.execute_reply": "2022-09-13T14:23:13.313508Z"
        },
        "trusted": true,
        "id": "Z2YnTQjSvfWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binning 'Cabin_1'"
      ],
      "metadata": {
        "id": "hb89-qYdvfWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Histogram of 'Cabin_1' by Plotly (interactive)\n",
        "fig = go.Figure()\n",
        "\n",
        "data0 = go.Histogram(\n",
        "    x=train_neg['Cabin_1'],\n",
        "    marker = dict(color='#0000FF'), # Blue\n",
        "    opacity=0.6,\n",
        "    name='Transporetd=0'\n",
        ")\n",
        "data1 = go.Histogram(\n",
        "    x=train_pos['Cabin_1'],\n",
        "    marker = dict(color='#FF0000'), # Red\n",
        "    opacity=0.6,\n",
        "    name='Transported=1'\n",
        ")\n",
        "\n",
        "fig.add_trace(data0)\n",
        "fig.add_trace(data1)\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis = dict(title='Cabin_1'),\n",
        "    yaxis = dict(title='Count')\n",
        ")\n",
        "fig.update_layout(barmode='overlay')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.316113Z",
          "iopub.execute_input": "2022-09-13T14:23:13.316431Z",
          "iopub.status.idle": "2022-09-13T14:23:13.336166Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.316402Z",
          "shell.execute_reply": "2022-09-13T14:23:13.334824Z"
        },
        "trusted": true,
        "id": "I7KVRlVDvfWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Binning 'Cabin_1' based on the above graph\n",
        "cabin_1_bins = np.array([0, 300, 600, 1150, 1500, 1700, 2000])\n",
        "train['Cabin_1'] = pd.cut(train['Cabin_1'], bins=cabin_1_bins, labels=False, right=False)\n",
        "\n",
        "## Distribution of 'Cabin_1' after Binning\n",
        "sns.countplot(x='Cabin_1', data=train, hue='Transported')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.337783Z",
          "iopub.execute_input": "2022-09-13T14:23:13.338266Z",
          "iopub.status.idle": "2022-09-13T14:23:13.646921Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.338211Z",
          "shell.execute_reply": "2022-09-13T14:23:13.645958Z"
        },
        "trusted": true,
        "id": "e1_xhsSFvfWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"3.2\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.2 Dataset </center></h2>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "ZAe17ncPvfWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Data Processing</center></h2>"
      ],
      "metadata": {
        "id": "KKAxg46pvfWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns_0 = ['Age', 'RoomService', 'FoodCourt',\n",
        "                     'ShoppingMall', 'Spa', 'VRDeck']\n",
        "numerical_columns_1 = ['Age', 'RoomService', 'FoodCourt',\n",
        "                     'ShoppingMall', 'Spa', 'VRDeck', 'Cabin_1']\n",
        "categorical_columns_0 = ['PassengerId', 'HomePlanet', 'CryoSleep',\n",
        "                       'Cabin', 'Destination', 'VIP', 'Name']\n",
        "categorical_columns_1 = ['PassengerId', 'HomePlanet', 'CryoSleep',\n",
        "                       'Cabin', 'Destination', 'VIP', 'Name',\n",
        "                       'Cabin_0', 'Cabin_2']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.648325Z",
          "iopub.execute_input": "2022-09-13T14:23:13.649459Z",
          "iopub.status.idle": "2022-09-13T14:23:13.655893Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.64942Z",
          "shell.execute_reply": "2022-09-13T14:23:13.654588Z"
        },
        "trusted": true,
        "id": "sbWNZY3XvfWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Before filling null values,ã€€making the string 'nan' (transformed by astype(str) in preprocess_df() function) back to np.nan.\n",
        "for column in ['CryoSleep', 'VIP', 'HomePlanet', 'Destination', 'Cabin_0', 'Cabin_2']:\n",
        "    train[column] = train[column].map(lambda x: np.nan if x=='nan' else x)\n",
        "\n",
        "## Filling null values with mode\n",
        "train = train.fillna(train.mode().iloc[0])\n",
        "\n",
        "for numerical in numerical_columns_1:\n",
        "    train[numerical] = train[numerical].astype('int64')\n",
        "\n",
        "train.info()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.657355Z",
          "iopub.execute_input": "2022-09-13T14:23:13.657734Z",
          "iopub.status.idle": "2022-09-13T14:23:13.725944Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.657693Z",
          "shell.execute_reply": "2022-09-13T14:23:13.724769Z"
        },
        "trusted": true,
        "id": "gPKmYufTvfWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test Data Processing\n",
        "test = preprocess_df(test_df)\n",
        "test = cabin_split(test)\n",
        "\n",
        "test = clipping_quantile(test, quantile_values=train_quantile_values.loc[0.99])\n",
        "test, _ = binning(test, numerical_columns_0, n_bins, thresholds=train_split_bins)\n",
        "test['Cabin_1'] = pd.cut(test['Cabin_1'], bins=cabin_1_bins, labels=False, right=False)\n",
        "\n",
        "for column in ['CryoSleep', 'VIP', 'HomePlanet', 'Destination', 'Cabin_0', 'Cabin_2']:\n",
        "    test[column] = test[column].map(lambda x: np.nan if x=='nan' else x)\n",
        "\n",
        "test = test.fillna(train.mode().iloc[0])\n",
        "\n",
        "for numerical in numerical_columns_1:\n",
        "    test[numerical] = test[numerical].astype('int64')\n",
        "\n",
        "test.info()"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.731918Z",
          "iopub.execute_input": "2022-09-13T14:23:13.732302Z",
          "iopub.status.idle": "2022-09-13T14:23:13.821652Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.732267Z",
          "shell.execute_reply": "2022-09-13T14:23:13.820251Z"
        },
        "trusted": true,
        "id": "eSTg_lC4vfWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Validation Split</center></h2>"
      ],
      "metadata": {
        "id": "SZuPACQOvfWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Split train samples for cross-validation\n",
        "n_splits = exp_config['n_splits']\n",
        "skf = StratifiedKFold(n_splits=n_splits)\n",
        "train['k_folds'] = -1\n",
        "for fold, (train_idx, valid_idx) in enumerate(\n",
        "    skf.split(X=train, y=train['Transported'])\n",
        "):\n",
        "    train['k_folds'][valid_idx] = fold\n",
        "\n",
        "## Check split samples\n",
        "for i in range(n_splits):\n",
        "    print(f\"fold {i}: {len(train.query('k_folds==@i'))} samples\")"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.824116Z",
          "iopub.execute_input": "2022-09-13T14:23:13.824841Z",
          "iopub.status.idle": "2022-09-13T14:23:13.856597Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.824794Z",
          "shell.execute_reply": "2022-09-13T14:23:13.855747Z"
        },
        "trusted": true,
        "id": "yubWiEi9vfWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hold-out validation\n",
        "valid_fold = train.query(f'k_folds == 0').reset_index(drop=True)\n",
        "train_fold = train.query(f'k_folds != 0').reset_index(drop=True)\n",
        "print(len(train_fold), len(valid_fold))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.857838Z",
          "iopub.execute_input": "2022-09-13T14:23:13.858369Z",
          "iopub.status.idle": "2022-09-13T14:23:13.872344Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.858332Z",
          "shell.execute_reply": "2022-09-13T14:23:13.871098Z"
        },
        "trusted": true,
        "id": "xziXNckIvfWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Dataset and DataLoader</center></h2>"
      ],
      "metadata": {
        "id": "q7FWwS1SvfWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## After binning, all features are categorical.\n",
        "numerical_columns = []\n",
        "categorical_columns = ['Age', 'RoomService', 'FoodCourt',\n",
        "                       'ShoppingMall', 'Spa', 'VRDeck',\n",
        "                       'HomePlanet', 'CryoSleep',\n",
        "                       'Destination', 'VIP',\n",
        "                       'Cabin_0', 'Cabin_1', 'Cabin_2']\n",
        "\n",
        "## Making Lookup table of categorical featurs and target\n",
        "## Using sklearn.preprocessing.OrdinalEncoder\n",
        "oe = OrdinalEncoder(handle_unknown='error',\n",
        "                    dtype=np.int64)\n",
        "\n",
        "encoded = oe.fit_transform(train_fold[categorical_columns].values)\n",
        "#decoded = oe.inverse_transform(encoded)\n",
        "train_fold[categorical_columns] = encoded\n",
        "\n",
        "valid_fold[categorical_columns] = oe.transform(valid_fold[categorical_columns].values)\n",
        "train[categorical_columns] = oe.transform(train[categorical_columns].values)\n",
        "test[categorical_columns] = oe.transform(test[categorical_columns].values)\n",
        "\n",
        "encoder_categories = oe.categories_\n",
        "encoder_categories"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.874655Z",
          "iopub.execute_input": "2022-09-13T14:23:13.878017Z",
          "iopub.status.idle": "2022-09-13T14:23:13.992128Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.877982Z",
          "shell.execute_reply": "2022-09-13T14:23:13.991219Z"
        },
        "trusted": true,
        "id": "6Yxqsd7lvfWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset\n",
        "class SpaceshipDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, numerical_columns,\n",
        "                 categorical_columns, target=None):\n",
        "        self.df = df\n",
        "        self.numerical_columns = numerical_columns\n",
        "        self.categorical_columns = categorical_columns\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = {}\n",
        "\n",
        "        for nc in self.numerical_columns:\n",
        "            x = torch.tensor(self.df[nc][index],\n",
        "                             dtype=torch.float32)\n",
        "            x = torch.unsqueeze(x, dim=0)\n",
        "            data[nc] = x\n",
        "\n",
        "        for cc in self.categorical_columns:\n",
        "            x = torch.tensor(self.df[cc][index],\n",
        "                             dtype=torch.int32)\n",
        "            x = torch.unsqueeze(x, dim=0)\n",
        "            data[cc] = x\n",
        "\n",
        "        if self.target is not None:\n",
        "            label = torch.tensor(self.df[self.target][index],\n",
        "                                 dtype=torch.float32)\n",
        "            label = torch.unsqueeze(label, dim=-1)\n",
        "            return data, label\n",
        "        else:\n",
        "            return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:13.993473Z",
          "iopub.execute_input": "2022-09-13T14:23:13.994428Z",
          "iopub.status.idle": "2022-09-13T14:23:14.004748Z",
          "shell.execute_reply.started": "2022-09-13T14:23:13.994393Z",
          "shell.execute_reply": "2022-09-13T14:23:14.003455Z"
        },
        "trusted": true,
        "id": "HelcAZ6xvfWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Datasets\n",
        "train_ds = SpaceshipDataset(\n",
        "    train_fold,\n",
        "    numerical_columns,\n",
        "    categorical_columns,\n",
        "    target='Transported'\n",
        ")\n",
        "\n",
        "val_ds = SpaceshipDataset(\n",
        "    valid_fold,\n",
        "    numerical_columns,\n",
        "    categorical_columns,\n",
        "    target='Transported'\n",
        ")\n",
        "\n",
        "test_ds = SpaceshipDataset(\n",
        "    test,\n",
        "    numerical_columns,\n",
        "    categorical_columns,\n",
        "    target=None\n",
        ")\n",
        "\n",
        "## Operation Check\n",
        "index = 0\n",
        "print(train_ds.__getitem__(index))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.006447Z",
          "iopub.execute_input": "2022-09-13T14:23:14.006814Z",
          "iopub.status.idle": "2022-09-13T14:23:14.034613Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.006782Z",
          "shell.execute_reply": "2022-09-13T14:23:14.033229Z"
        },
        "trusted": true,
        "id": "9Wb-muFmvfWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create DataLoaders\n",
        "batch_size = exp_config['batch_size']\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "val_dl = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_dl = torch.utils.data.DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "dl_dict = {'train': train_dl, 'val': val_dl}\n",
        "\n",
        "## Operation Check\n",
        "sample_data, sample_label = next(iter(dl_dict['train']))\n",
        "input_dtypes = {}\n",
        "for key in sample_data:\n",
        "    input_dtypes[key] = sample_data[key].dtype\n",
        "    print(f'{key}, shape:{sample_data[key].shape}, dtype:{sample_data[key].dtype}')\n",
        "\n",
        "print('Label shape: ', sample_label.shape)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.036669Z",
          "iopub.execute_input": "2022-09-13T14:23:14.037446Z",
          "iopub.status.idle": "2022-09-13T14:23:14.170719Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.037399Z",
          "shell.execute_reply": "2022-09-13T14:23:14.16951Z"
        },
        "trusted": true,
        "id": "qVhSqas9vfWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"4\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>4. Model</center></h1>"
      ],
      "metadata": {
        "id": "pZyF_PbdvfWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"4.1\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.1 Preprocessing Model</center></h2>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "GzB7P3nqvfWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Preprocessing model recieves input data from the dataset, and handles numerical and categorical features respectively. Numerical features are gathered in a tensor. Categorical features are transformed into uniform shaped tensors by learnable embedding layers."
      ],
      "metadata": {
        "id": "roBOPymGvfWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor(nn.Module):\n",
        "    def __init__(self, numerical_columns, categorical_columns, encoder_categories, emb_dim):\n",
        "        super().__init__()\n",
        "        self.numerical_columns = numerical_columns\n",
        "        self.categorical_columns = categorical_columns\n",
        "        self.encoder_categories = encoder_categories\n",
        "        self.emb_dim = emb_dim\n",
        "        self.embed_layers = nn.ModuleDict()\n",
        "\n",
        "        for i, categorical in enumerate(categorical_columns):\n",
        "            embedding = nn.Embedding(\n",
        "                num_embeddings=len(self.encoder_categories[i]),\n",
        "                embedding_dim=self.emb_dim,\n",
        "            )\n",
        "            self.embed_layers[categorical] = embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_nums = []\n",
        "        for numerical in self.numerical_columns:\n",
        "            x_num = torch.unsqueeze(x[numerical], dim=1)\n",
        "            x_nums.append(x_num)\n",
        "        if len(x_nums) > 0:\n",
        "            x_nums = torch.cat(x_nums, dim=1)\n",
        "        else:\n",
        "            x_nums = torch.tensor(x_nums, dtype=torch.float32)\n",
        "\n",
        "        x_cats = []\n",
        "        for categorical in self.categorical_columns:\n",
        "            x_cat = self.embed_layers[categorical](x[categorical])\n",
        "            x_cats.append(x_cat)\n",
        "        if len(x_cats) > 0:\n",
        "            x_cats = torch.cat(x_cats, dim=1)\n",
        "        else:\n",
        "            x_cats = torch.tensor(x_cats, dtype=torch.float32)\n",
        "\n",
        "        return x_nums, x_cats\n",
        "\n",
        "## Operation Check\n",
        "preprocessor = Preprocessor(numerical_columns,\n",
        "                            categorical_columns,\n",
        "                            encoder_categories,\n",
        "                            emb_dim=3)\n",
        "x_nums, x_cats = preprocessor(sample_data)\n",
        "x_nums.shape, x_cats.shape"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.172253Z",
          "iopub.execute_input": "2022-09-13T14:23:14.172943Z",
          "iopub.status.idle": "2022-09-13T14:23:14.199506Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.172873Z",
          "shell.execute_reply": "2022-09-13T14:23:14.198557Z"
        },
        "trusted": true,
        "id": "4peCDTFLvfWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"4.2\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.2 TabTransformer</center></h2>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "8ECyzWLyvfWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tab Transformer\n",
        "\n",
        "Again, the architecture of TabTransformer is as follows:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/keras-team/keras-io/master/examples/structured_data/img/tabtransformer/tabtransformer.png\" width=\"400\"/>\n",
        "\n",
        "The TabTransformer architecture comprises a column embedding layer, a stack of $N$ Transformer layers, and a multi-layer perceptron (MLP).\n",
        "\n",
        "- **Column embedding layer:** All the categorical features are encoded into parametric embeddings, of same dimensions. This means that each value in each categorical feature will have its own embedding vector.\n",
        "\n",
        "- **Transformer layer:** The embedded categorical features are fed into a stack of Transformer blocks. Each Transformer block consists of a multi-head self-attention layer followed by a position-wise feed-forward layer. Parametric embeddings are transformed into contextual embeddings through the Transformer blocks.\n",
        "\n",
        " - **Self-attention layer:** A self-attention layer comprises three parametric matrices - Key, Query and Value. Each input embedding is projected on to these matrices, to generate their key ($K \\in \\mathbb{R}^{m \\times k}$), query ($Q \\in \\mathbb{R}^{m \\times k}$) and value ($V \\in \\mathbb{R}^{m \\times v}$) vectors.\n",
        "\n",
        " $$\n",
        " \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{k}})V\n",
        " $$\n",
        "\n",
        " - **Feed-forward layer:** Through two position-wise feed-forward layers, embeddings are expanded to four times its size and projected back to its original size. When using ReLU activation, feed-forward network's formula is as follows:\n",
        "\n",
        " $$\n",
        " \\text{FFN}(x) = \\text{max}(0, \\: x W_1 + b_1) W_2 + b_2\n",
        " $$\n",
        "\n",
        "- **MLP:** The outputs of the last Transformer layer, which are contextualized embeddings of the categorical features, are concatenated along with the numerical input features to form a final feature vector. This vecter is inputted into an MLP to predict the target."
      ],
      "metadata": {
        "id": "7sHw1U9kvfWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, n_features, hidden_units,\n",
        "                 dropout_rates):\n",
        "        super().__init__()\n",
        "        self.mlp_layers = nn.Sequential()\n",
        "        num_features = n_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            self.mlp_layers.add_module(f'norm_{i}', nn.BatchNorm1d(num_features))\n",
        "            self.mlp_layers.add_module(f'dense_{i}', nn.Linear(num_features, units))\n",
        "            self.mlp_layers.add_module(f'act_{i}', nn.SELU())\n",
        "            self.mlp_layers.add_module(f'dropout_{i}', nn.Dropout(dropout_rates[i]))\n",
        "            num_features = units\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.mlp_layers(x)\n",
        "        return y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.201152Z",
          "iopub.execute_input": "2022-09-13T14:23:14.203144Z",
          "iopub.status.idle": "2022-09-13T14:23:14.212178Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.203106Z",
          "shell.execute_reply": "2022-09-13T14:23:14.210905Z"
        },
        "trusted": true,
        "id": "txycpWPovfWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabTransformerBlock(nn.Module):\n",
        "    def __init__(self, num_heads, emb_dim,\n",
        "                 attn_dropout_rate, ff_dropout_rate):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(emb_dim, num_heads,\n",
        "                                          dropout=attn_dropout_rate,\n",
        "                                          batch_first=True)\n",
        "        self.norm_1 = nn.LayerNorm(emb_dim)\n",
        "        self.norm_2 = nn.LayerNorm(emb_dim)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, emb_dim*4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(ff_dropout_rate),\n",
        "            nn.Linear(emb_dim*4, emb_dim))\n",
        "\n",
        "    def forward(self, x_cat):\n",
        "        attn_output, attn_output_weights = self.attn(x_cat, x_cat, x_cat)\n",
        "        x_skip_1 = x_cat + attn_output\n",
        "        x_skip_1 = self.norm_1(x_skip_1)\n",
        "        feedforward_output = self.feedforward(x_skip_1)\n",
        "        x_skip_2 = x_skip_1 + feedforward_output\n",
        "        x_skip_2 = self.norm_2(x_skip_2)\n",
        "        return x_skip_2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.213362Z",
          "iopub.execute_input": "2022-09-13T14:23:14.214524Z",
          "iopub.status.idle": "2022-09-13T14:23:14.226017Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.214487Z",
          "shell.execute_reply": "2022-09-13T14:23:14.22497Z"
        },
        "trusted": true,
        "id": "mjS0WR9AvfWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabTransformer(nn.Module):\n",
        "    def __init__(self, numerical_columns, categorical_columns,\n",
        "                 num_transformer_blocks, num_heads, emb_dim,\n",
        "                 attn_dropout_rates, ff_dropout_rates,\n",
        "                 mlp_dropout_rates,\n",
        "                 mlp_hidden_units_factors,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.transformers = nn.Sequential()\n",
        "        for i in range(num_transformer_blocks):\n",
        "            self.transformers.add_module(f'transformer_{i}',\n",
        "                                        TabTransformerBlock(num_heads,\n",
        "                                                            emb_dim,\n",
        "                                                            attn_dropout_rates[i],\n",
        "                                                            ff_dropout_rates[i]))\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.num_norm = nn.LayerNorm(len(numerical_columns))\n",
        "\n",
        "        self.n_features = (len(categorical_columns) * emb_dim) + len(numerical_columns)\n",
        "        mlp_hidden_units = [int(factor * self.n_features) \\\n",
        "                            for factor in mlp_hidden_units_factors]\n",
        "        self.mlp = MLPBlock(self.n_features, mlp_hidden_units,\n",
        "                            mlp_dropout_rates)\n",
        "\n",
        "        self.final_dense = nn.Linear(mlp_hidden_units[-1], 1)\n",
        "        self.final_sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x_nums, x_cats):\n",
        "        contextualized_x_cats = self.transformers(x_cats)\n",
        "        contextualized_x_cats = self.flatten(contextualized_x_cats)\n",
        "\n",
        "        if x_nums.shape[-1] > 0:\n",
        "            x_nums = self.num_norm(x_nums)\n",
        "            features = torch.cat((x_nums, contextualized_x_cats), -1)\n",
        "        else:\n",
        "            features = contextualized_x_cats\n",
        "\n",
        "        mlp_output = self.mlp(features)\n",
        "        model_output = self.final_dense(mlp_output)\n",
        "        output = self.final_sigmoid(model_output)\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.227621Z",
          "iopub.execute_input": "2022-09-13T14:23:14.228414Z",
          "iopub.status.idle": "2022-09-13T14:23:14.240351Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.228379Z",
          "shell.execute_reply": "2022-09-13T14:23:14.238955Z"
        },
        "trusted": true,
        "id": "BD3lFT_UvfWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TabTransformer Model Check\n",
        "\n",
        "## Settings for TabTransformer\n",
        "emb_dim = model_config['cat_embedding_dim']\n",
        "num_transformer_blocks = model_config['num_transformer_blocks']\n",
        "num_heads = model_config['num_heads']\n",
        "attn_dropout_rates = model_config['tf_dropout_rates']\n",
        "ff_dropout_rates = model_config['ff_dropout_rates']\n",
        "mlp_dropout_rates = model_config['mlp_dropout_rates']\n",
        "mlp_hidden_units_factors = model_config['mlp_hidden_units_factors']\n",
        "\n",
        "## Building Models\n",
        "preprocessor = Preprocessor(numerical_columns, categorical_columns,\n",
        "                            encoder_categories, emb_dim)\n",
        "\n",
        "model = TabTransformer(numerical_columns, categorical_columns,\n",
        "                       num_transformer_blocks, num_heads, emb_dim,\n",
        "                       attn_dropout_rates, ff_dropout_rates,\n",
        "                       mlp_dropout_rates, mlp_hidden_units_factors)\n",
        "\n",
        "## Operation, Parameters and Model Structure Check\n",
        "x_nums, x_cats = preprocessor(sample_data)\n",
        "y = model(x_nums, x_cats)\n",
        "print('Numerical Input shape: ', x_nums.shape)\n",
        "print('Categorical Input shape: ', x_cats.shape)\n",
        "print('Output shape: ', y.shape)\n",
        "\n",
        "print('# of Preprocessor parameters: ',\n",
        "      sum(p.numel() for p in preprocessor.parameters() if p.requires_grad))\n",
        "print('# of N-BEATS parameters: ',\n",
        "      sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "model"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.241783Z",
          "iopub.execute_input": "2022-09-13T14:23:14.242211Z",
          "iopub.status.idle": "2022-09-13T14:23:14.390849Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.242177Z",
          "shell.execute_reply": "2022-09-13T14:23:14.389905Z"
        },
        "trusted": true,
        "id": "lTW8H-lWvfWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"5\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>5. Training</center></h1>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "PmcCQZs3vfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loss Function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "## Optimizer and Learning Rate Scheduler\n",
        "epochs = exp_config['train_epochs']\n",
        "batch_size = exp_config['batch_size']\n",
        "steps_per_epoch = len(train_fold) // batch_size\n",
        "\n",
        "learning_rate = exp_config['learning_rate']\n",
        "weight_decay = exp_config['weight_decay']\n",
        "params = list(preprocessor.parameters()) + list(model.parameters())\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=params,\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer=optimizer,\n",
        "    T_max=epochs*steps_per_epoch\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.391963Z",
          "iopub.execute_input": "2022-09-13T14:23:14.392666Z",
          "iopub.status.idle": "2022-09-13T14:23:14.4008Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.392628Z",
          "shell.execute_reply": "2022-09-13T14:23:14.399717Z"
        },
        "trusted": true,
        "id": "mOpKNABbvfWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Displaying Learning Rate\n",
        "def lr_plot(lr_scheduler, steps):\n",
        "    lrs = []\n",
        "    for _ in range(steps):\n",
        "        optimizer.step()\n",
        "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "        lr_scheduler.step()\n",
        "    xs = [i+1 for i in range(steps)]\n",
        "    plt.figure(figsize=(7,5))\n",
        "    ax = sns.lineplot(xs, lrs)\n",
        "    ax.set_xlabel('Steps')\n",
        "    ax.set_ylabel('Learning Rate')\n",
        "\n",
        "lr_plot(lr_scheduler, epochs*steps_per_epoch)\n",
        "\n",
        "## Create New Optimizer and Lr_scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=params,\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer=optimizer,\n",
        "    T_max=epochs*steps_per_epoch\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.402566Z",
          "iopub.execute_input": "2022-09-13T14:23:14.403327Z",
          "iopub.status.idle": "2022-09-13T14:23:14.746737Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.40328Z",
          "shell.execute_reply": "2022-09-13T14:23:14.74565Z"
        },
        "trusted": true,
        "id": "oGiQae3kvfWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function for the Model Training\n",
        "def train_model(model, preprocessor,\n",
        "                dl_dict, criterion,\n",
        "                optimizer, lr_scheduler,\n",
        "                num_epochs, finalize=False):\n",
        "    ## Checking usability of GUP\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'device: {device}')\n",
        "    print('-------Start Training-------')\n",
        "    model.to(device)\n",
        "    ## We use preprocessor on CPU\n",
        "\n",
        "    ## training and validation loop\n",
        "    if finalize:\n",
        "        phases = ['train']\n",
        "    else:\n",
        "        phases = ['train', 'val']\n",
        "\n",
        "    losses = {phase: [] for phase in phases}\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in phases:\n",
        "            if phase == 'train':\n",
        "                preprocessor.train()\n",
        "                model.train()\n",
        "            else:\n",
        "                preprocessor.eval()\n",
        "                model.eval()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            epoch_corrects = 0\n",
        "\n",
        "            for data, labels in tqdm(dl_dict[phase]):\n",
        "                x_nums, x_cats = preprocessor(data)\n",
        "\n",
        "                x_nums = x_nums.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                ## Optimizer Initialization\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                ## Forward Processing\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    outputs = model(x_nums, x_cats)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    preds = torch.where(outputs>0.5, 1., 0.)\n",
        "\n",
        "                    ## Backward Processing and Optimization\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        lr_scheduler.step()\n",
        "\n",
        "                    epoch_loss += loss.item() * x_cats.size(0)\n",
        "                    epoch_corrects += torch.sum(preds == labels)\n",
        "\n",
        "            epoch_loss = epoch_loss / len(dl_dict[phase].dataset)\n",
        "            losses[phase].append(epoch_loss)\n",
        "            epoch_acc = epoch_corrects / len(dl_dict[phase].dataset)\n",
        "\n",
        "            ## Displaying results\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.\\\n",
        "                  format(epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return model, preprocessor, losses"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.748218Z",
          "iopub.execute_input": "2022-09-13T14:23:14.748626Z",
          "iopub.status.idle": "2022-09-13T14:23:14.762592Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.748586Z",
          "shell.execute_reply": "2022-09-13T14:23:14.761395Z"
        },
        "trusted": true,
        "id": "uywU-rj6vfWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Function for Plotting Losses\n",
        "def plot_losses(losses, title=None):\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    losses = pd.DataFrame(losses)\n",
        "    losses.index = [i+1 for i in range(len(losses))]\n",
        "    ax = sns.lineplot(data=losses)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.legend()\n",
        "    ax.set_title(title)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.764444Z",
          "iopub.execute_input": "2022-09-13T14:23:14.76485Z",
          "iopub.status.idle": "2022-09-13T14:23:14.776742Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.764816Z",
          "shell.execute_reply": "2022-09-13T14:23:14.775532Z"
        },
        "trusted": true,
        "id": "s2vwq-fMvfWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training\n",
        "model_trained, preprocessor_trained, losses = train_model(\n",
        "    model,\n",
        "    preprocessor,\n",
        "    dl_dict,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    lr_scheduler,\n",
        "    epochs\n",
        ")\n",
        "\n",
        "## Plot Losses\n",
        "plot_losses(losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:23:14.778468Z",
          "iopub.execute_input": "2022-09-13T14:23:14.779102Z",
          "iopub.status.idle": "2022-09-13T14:24:05.212371Z",
          "shell.execute_reply.started": "2022-09-13T14:23:14.779068Z",
          "shell.execute_reply": "2022-09-13T14:24:05.211247Z"
        },
        "trusted": true,
        "id": "c2BYr8VEvfWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"background:#D4F1F4; border:0; border-radius: 12px; color:black\"><center>Finalizing Training</center></h2>"
      ],
      "metadata": {
        "id": "QN_-vRahvfWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Finalizing Training\n",
        "if exp_config['finalize']:\n",
        "\n",
        "    ## Making Dataset and DataLoader for Finalizing\n",
        "    train_all_ds = SpaceshipDataset(\n",
        "        train,\n",
        "        numerical_columns,\n",
        "        categorical_columns,\n",
        "        target='Transported'\n",
        "    )\n",
        "\n",
        "    train_all_dl = torch.utils.data.DataLoader(\n",
        "        train_all_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    finalize_dl_dict = {'train': train_all_dl}\n",
        "\n",
        "    ## Building Models\n",
        "    preprocessor = Preprocessor(\n",
        "        numerical_columns,\n",
        "        categorical_columns,\n",
        "        encoder_categories,\n",
        "        emb_dim\n",
        "    )\n",
        "\n",
        "    model = TabTransformer(\n",
        "        numerical_columns,\n",
        "        categorical_columns,\n",
        "        num_transformer_blocks,\n",
        "        num_heads, emb_dim,\n",
        "        attn_dropout_rates,\n",
        "        ff_dropout_rates,\n",
        "        mlp_dropout_rates,\n",
        "        mlp_hidden_units_factors\n",
        "    )\n",
        "\n",
        "    ## Loss Function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    ## Optimizer and Learning Rate Scheduler\n",
        "    epochs = exp_config['finalize_epochs']\n",
        "    batch_size = exp_config['batch_size']\n",
        "    steps_per_epoch = len(train_fold) // batch_size\n",
        "\n",
        "    learning_rate = exp_config['learning_rate']\n",
        "    weight_decay = exp_config['weight_decay']\n",
        "    params = list(preprocessor.parameters()) + list(model.parameters())\n",
        "    optimizer = torch.optim.AdamW(params=params,\n",
        "                                  lr=learning_rate,\n",
        "                                  weight_decay=weight_decay)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer=optimizer,\n",
        "        T_max=epochs*steps_per_epoch\n",
        "    )\n",
        "\n",
        "    ## Training\n",
        "    model_trained, preprocessor_trained, losses = train_model(\n",
        "        model,\n",
        "        preprocessor,\n",
        "        finalize_dl_dict,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        lr_scheduler,\n",
        "        epochs,\n",
        "        finalize=True\n",
        "    )\n",
        "\n",
        "    ## Plot Losses\n",
        "    plot_losses(losses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:24:05.213697Z",
          "iopub.execute_input": "2022-09-13T14:24:05.214051Z",
          "iopub.status.idle": "2022-09-13T14:24:31.94377Z",
          "shell.execute_reply.started": "2022-09-13T14:24:05.214016Z",
          "shell.execute_reply": "2022-09-13T14:24:31.941238Z"
        },
        "trusted": true,
        "id": "UbY52hNJvfWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id =\"6\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>6. Prediction</center></h1>\n",
        "[Back to the TOC](#toc)"
      ],
      "metadata": {
        "id": "GvNdRWagvfWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "preprocessor_trained.eval()\n",
        "model_trained.eval()\n",
        "model_trained.to(device)\n",
        "\n",
        "probas = []\n",
        "\n",
        "for data in (test_dl):\n",
        "    x_nums, x_cats = preprocessor_trained(data)\n",
        "    x_nums = x_nums.to(device)\n",
        "    x_cats = x_cats.to(device)\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        outputs = model_trained(x_nums, x_cats)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        outputs = outputs.to('cpu').detach().numpy().copy()\n",
        "        probas.append(outputs)\n",
        "\n",
        "## post-processing\n",
        "probas = np.concatenate(probas)\n",
        "preds = np.where(probas > 0.5, True, False)\n",
        "submission_df['Transported'] = preds\n",
        "submission_df.to_csv('submission_cv.csv', index=False)\n",
        "submission_df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-13T14:24:31.94569Z",
          "iopub.execute_input": "2022-09-13T14:24:31.946152Z",
          "iopub.status.idle": "2022-09-13T14:24:33.050046Z",
          "shell.execute_reply.started": "2022-09-13T14:24:31.946098Z",
          "shell.execute_reply": "2022-09-13T14:24:33.048633Z"
        },
        "trusted": true,
        "id": "TpETjvjIvfW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### Work in Progress...\n",
        "\n",
        "I'm going to update this notebook in soon. Please come again and checkout the progress. Thank you for reading!"
      ],
      "metadata": {
        "id": "SeCSrcUBvfW0"
      }
    }
  ]
}